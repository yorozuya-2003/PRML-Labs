{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded57ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Node:\n",
    "    '''\n",
    "    Defines each node of the Decision Tree\n",
    "    '''\n",
    "    def __init__(self, feature=None, left=None, right=None, threshold=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value\n",
    "    \n",
    "    \n",
    "class DTClassifier:\n",
    "    '''\n",
    "    Decision Tree Classifier\n",
    "    '''\n",
    "    def __init__(self, max_depth=3, min_sample_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_sample_split = min_sample_split\n",
    "        \n",
    "        self.root_node = None\n",
    "        \n",
    "        \n",
    "    def build_tree(self, train_X, train_y, current_depth=0):\n",
    "        num_datapoints = len(train_X)\n",
    "        \n",
    "        if (num_datapoints >= self.min_sample_split) and (current_depth <= self.max_depth):\n",
    "            split = self.cont_to_cat(train_X, train_y)\n",
    "            \n",
    "            if split['info_gain'] > 0:\n",
    "                left_branch = self.build_tree(split['left_branch_X'], split['left_branch_y'], current_depth+1)\n",
    "                right_branch = self.build_tree(split['right_branch_X'], split['right_branch_y'], current_depth+1)\n",
    "                \n",
    "                return Node(feature=split['feature'],\n",
    "                            left=left_branch, right=right_branch, \n",
    "                            threshold=split['threshold'])\n",
    "                \n",
    "        # in case of leaf node\n",
    "        leaf_value = max(train_y)\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    \n",
    "    def cont_to_cat(self, train_X, train_y):\n",
    "        '''\n",
    "        Makes the best possible split based on the information gain (entropy loss) \n",
    "        '''\n",
    "        split = {}\n",
    "        info_gain = -1\n",
    "        \n",
    "        features = train_X.columns.tolist()\n",
    "        for Feature in features:\n",
    "            possible_thresholds = train_X[Feature].unique()\n",
    "            for Threshold in possible_thresholds:\n",
    "                # left branch\n",
    "                left_branch_X = train_X[train_X[Feature] <= Threshold]\n",
    "                left_branch_y = train_y[train_X[Feature] <= Threshold]\n",
    "                \n",
    "                # right branch\n",
    "                right_branch_X = train_X[train_X[Feature] > Threshold]\n",
    "                right_branch_y = train_y[train_X[Feature] > Threshold]\n",
    "                \n",
    "                if len(left_branch_X > 0) and len(right_branch_X > 0):\n",
    "                    current_info_gain = self.information_gain(train_y, left_branch_y, right_branch_y)\n",
    "                    \n",
    "                    if current_info_gain > info_gain:\n",
    "                        split['feature'] = Feature\n",
    "                        split['threshold'] = Threshold\n",
    "                        split['left_branch_X'] = left_branch_X\n",
    "                        split['left_branch_y'] = left_branch_y\n",
    "                        split['right_branch_X'] = right_branch_X\n",
    "                        split['right_branch_y'] = right_branch_y\n",
    "                        split['info_gain'] = current_info_gain\n",
    "                        info_gain = current_info_gain\n",
    "        \n",
    "        return split\n",
    "    \n",
    "    \n",
    "    def train(self, train_X, train_y):\n",
    "        self.root_node = self.build_tree(train_X, train_y)\n",
    "    \n",
    "    \n",
    "    def predict(self, test_X, node):\n",
    "        '''\n",
    "        Predicts the class for a single data point\n",
    "        (Recursive Function)\n",
    "        '''\n",
    "        if node.value != None:\n",
    "            return node.value\n",
    "        \n",
    "        node_feature = test_X[node.feature]\n",
    "        if node_feature <= node.threshold:\n",
    "            return self.predict(test_X, node.left)\n",
    "        else:\n",
    "            return self.predict(test_X, node.right)\n",
    "        \n",
    "        \n",
    "    def test(self, test_X, test_y):\n",
    "        '''\n",
    "        Returns the predictions and accuracy scored for the test dataset\n",
    "        '''\n",
    "        pred_y = []\n",
    "        Test_y = test_y.tolist()\n",
    "        for x in range(len(test_X)):\n",
    "            pred_y.append(self.predict(test_X.iloc[x], self.root_node))\n",
    "            \n",
    "        print('True Values:', Test_y)\n",
    "        print('Predictions:', pred_y)\n",
    "        \n",
    "        accuracy = 0\n",
    "        for each in range(len(pred_y)):\n",
    "            if pred_y[each] == Test_y[each]:\n",
    "                accuracy += 1\n",
    "        accuracy /= len(test_X)\n",
    "        print('Accuracy:', accuracy)\n",
    "        \n",
    "        classwise_accuracy = 0\n",
    "        classes = test_y.unique()\n",
    "        classwise_true_pos_count = {}\n",
    "        for Class in classes:\n",
    "            classwise_true_pos_count[Class] = 0\n",
    "            \n",
    "        classwise_count = test_y.value_counts().to_dict()\n",
    "        \n",
    "        for each in range(len(pred_y)):\n",
    "            if pred_y[each] == Test_y[each]:\n",
    "                Class = Test_y[each]\n",
    "                classwise_true_pos_count[Class] += 1\n",
    "        \n",
    "        for Class in classes:\n",
    "            classwise_accuracy += classwise_true_pos_count[Class]/classwise_count[Class]\n",
    "        \n",
    "        classwise_accuracy /= len(classes)\n",
    "        print('Classwise Accuracy:', classwise_accuracy)\n",
    "    \n",
    "    \n",
    "    def information_gain(self, y_node, y_left_branch, y_right_branch):\n",
    "        total_datapoints = len(y_node)\n",
    "        left_branch_weight = len(y_left_branch)/total_datapoints \n",
    "        right_branch_weight = (len(y_right_branch))/total_datapoints\n",
    "        \n",
    "        return self.entropy_loss(y_node) - \\\n",
    "            ( left_branch_weight*self.entropy_loss(y_left_branch) + right_branch_weight*self.entropy_loss(y_right_branch) )\n",
    "        \n",
    "        \n",
    "    def entropy_loss(self, y):\n",
    "        probs = y.value_counts().to_numpy()/len(y)\n",
    "        entropy = 0\n",
    "        for each in probs:\n",
    "            entropy += each * math.log2(each)\n",
    "\n",
    "        return -entropy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = DTClassifier()\n",
    "model.train(train_X, train_y)\n",
    "model.test(test_X, test_y)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
